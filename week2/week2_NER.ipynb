{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week2/week2-NER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgLPPDTNqc/PMY2Ron1oXB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9eb6e5fcda3e4461a1708059a500037a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_61bb7ee14aab4a958c696c72bf02e285",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_56c9649c967c490982f154eb87dc20fe",
              "IPY_MODEL_73af0befd3bc4ca7bc9182944e2215a1"
            ]
          }
        },
        "61bb7ee14aab4a958c696c72bf02e285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56c9649c967c490982f154eb87dc20fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c2172a838d3f480e88fe10a3ea545ff1",
            "_dom_classes": [],
            "description": "train.txt: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 849548,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 849548,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43505b0a0a7b4a0fa492e732b5daeb8b"
          }
        },
        "73af0befd3bc4ca7bc9182944e2215a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b0539953c1cd45eeb65d243f79a38a3b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 850k/850k [02:32&lt;00:00, 5.58kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70fff60eb54d4e57a35cda53be68ccd7"
          }
        },
        "c2172a838d3f480e88fe10a3ea545ff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43505b0a0a7b4a0fa492e732b5daeb8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0539953c1cd45eeb65d243f79a38a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70fff60eb54d4e57a35cda53be68ccd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc55df6272e149b6bc08fb71bb8003ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_477ffaa98cbd44f4b7c5e8623e95d252",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31e13506b7374736bfc8a15caa4a4f08",
              "IPY_MODEL_9837e7458b3f484587772174ec7b5286"
            ]
          }
        },
        "477ffaa98cbd44f4b7c5e8623e95d252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31e13506b7374736bfc8a15caa4a4f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_84dc16173e474953b0edad2e77582fed",
            "_dom_classes": [],
            "description": "validation.txt: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 103771,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 103771,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09f9e44e616d44abb2706fe925720333"
          }
        },
        "9837e7458b3f484587772174ec7b5286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_33a9e6af2491487192429d05a20eedc9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 104k/104k [00:00&lt;00:00, 258kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6c9c2abd7684f27944bde8396354cbd"
          }
        },
        "84dc16173e474953b0edad2e77582fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09f9e44e616d44abb2706fe925720333": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33a9e6af2491487192429d05a20eedc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6c9c2abd7684f27944bde8396354cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4d9f0218fc445a6bd051d49f205375b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_62753742b31147d1bca9ef1e0578ddc4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_965d27f9623d42e49089325e176add73",
              "IPY_MODEL_1c8d52cf39874682955f9aec63b14bf2"
            ]
          }
        },
        "62753742b31147d1bca9ef1e0578ddc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "965d27f9623d42e49089325e176add73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_292696ff49554f8785cca07e35a65fd9",
            "_dom_classes": [],
            "description": "test.txt: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 106837,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 106837,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86f78397164f4364a0464b966de0d01b"
          }
        },
        "1c8d52cf39874682955f9aec63b14bf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_801c71959adf4c2aa5f90bd0ab37ad0c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 107k/107k [02:05&lt;00:00, 849B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_345115eb154b4e2b9c929f0c49ed1889"
          }
        },
        "292696ff49554f8785cca07e35a65fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86f78397164f4364a0464b966de0d01b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "801c71959adf4c2aa5f90bd0ab37ad0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "345115eb154b4e2b9c929f0c49ed1889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kySheryl/Natural-Language-Processing-Coursera-/blob/master/week2/week2_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4-d8Az_y7Wd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "9ac30542-8527-4d32-8b6c-924e8b1dc4eb"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/hse-aml/natural-language-processing/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()  \n",
        "setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "# setup_google_colab.setup_project()\n",
        "# setup_google_colab.setup_honor()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-06 06:24:20--  https://raw.githubusercontent.com/hse-aml/natural-language-processing/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1991 (1.9K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   1.94K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-07-06 06:24:21 (28.8 MB/s) - ‘setup_google_colab.py’ saved [1991/1991]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS-DMevuy-uK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==1.15.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrAX468YzUDo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348,
          "referenced_widgets": [
            "9eb6e5fcda3e4461a1708059a500037a",
            "61bb7ee14aab4a958c696c72bf02e285",
            "56c9649c967c490982f154eb87dc20fe",
            "73af0befd3bc4ca7bc9182944e2215a1",
            "c2172a838d3f480e88fe10a3ea545ff1",
            "43505b0a0a7b4a0fa492e732b5daeb8b",
            "b0539953c1cd45eeb65d243f79a38a3b",
            "70fff60eb54d4e57a35cda53be68ccd7",
            "dc55df6272e149b6bc08fb71bb8003ac",
            "477ffaa98cbd44f4b7c5e8623e95d252",
            "31e13506b7374736bfc8a15caa4a4f08",
            "9837e7458b3f484587772174ec7b5286",
            "84dc16173e474953b0edad2e77582fed",
            "09f9e44e616d44abb2706fe925720333",
            "33a9e6af2491487192429d05a20eedc9",
            "b6c9c2abd7684f27944bde8396354cbd",
            "d4d9f0218fc445a6bd051d49f205375b",
            "62753742b31147d1bca9ef1e0578ddc4",
            "965d27f9623d42e49089325e176add73",
            "1c8d52cf39874682955f9aec63b14bf2",
            "292696ff49554f8785cca07e35a65fd9",
            "86f78397164f4364a0464b966de0d01b",
            "801c71959adf4c2aa5f90bd0ab37ad0c",
            "345115eb154b4e2b9c929f0c49ed1889"
          ]
        },
        "outputId": "092aded3-972e-4d30-f5d7-69ce5a1b1366"
      },
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    ! wget https://raw.githubusercontent.com/hse-aml/natural-language-processing/master/setup_google_colab.py -O setup_google_colab.py\n",
        "    import setup_google_colab\n",
        "    setup_google_colab.setup_week2()\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from common.download_utils import download_week2_resources\n",
        "\n",
        "download_week2_resources()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-06 06:27:48--  https://raw.githubusercontent.com/hse-aml/natural-language-processing/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1991 (1.9K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   1.94K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-07-06 06:27:48 (31.5 MB/s) - ‘setup_google_colab.py’ saved [1991/1991]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9eb6e5fcda3e4461a1708059a500037a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=849548.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc55df6272e149b6bc08fb71bb8003ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=103771.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4d9f0218fc445a6bd051d49f205375b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=106837.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYbXuS3HzyRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(file_path):\n",
        "    tokens = []\n",
        "    tags = []\n",
        "    \n",
        "    tweet_tokens = []\n",
        "    tweet_tags = []\n",
        "    for line in open(file_path, encoding='utf-8'):\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            if tweet_tokens:\n",
        "                tokens.append(tweet_tokens)\n",
        "                tags.append(tweet_tags)\n",
        "            tweet_tokens = []\n",
        "            tweet_tags = []\n",
        "        else:\n",
        "            token, tag = line.split()\n",
        "            # Replace all urls with <URL> token\n",
        "            # Replace all users with <USR> token\n",
        "\n",
        "            ######################################\n",
        "            ######### YOUR CODE HERE #############\n",
        "            if token[:7] == 'http://' or token[:8] == 'https://':\n",
        "              token = '<URL>'\n",
        "            elif token[0]=='@':\n",
        "              token = '<USR>'\n",
        "            ######################################\n",
        "            \n",
        "            tweet_tokens.append(token)\n",
        "            tweet_tags.append(tag)\n",
        "            \n",
        "            \n",
        "    return tokens, tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riZGd9s30ZmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tokens, train_tags = read_data('data/train.txt')\n",
        "validation_tokens, validation_tags = read_data('data/validation.txt')\n",
        "test_tokens, test_tags = read_data('data/test.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR6C9OKs0e2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(3):\n",
        "    for token, tag in zip(train_tokens[i], train_tags[i]):\n",
        "        print('%s\\t%s' % (token, tag))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgMEuM7g1rYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6D6oVkG2mIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_dict(tokens_or_tags, special_tokens):\n",
        "    \"\"\"\n",
        "        tokens_or_tags: a list of lists of tokens or tags\n",
        "        special_tokens: some special tokens\n",
        "    \"\"\"\n",
        "    # Create a dictionary with default value 0\n",
        "    tok2idx = defaultdict(lambda: 0)\n",
        "    idx2tok = []\n",
        "    \n",
        "    # Create mappings from tokens (or tags) to indices and vice versa.\n",
        "    # At first, add special tokens (or tags) to the dictionaries.\n",
        "    # The first special token must have index 0.\n",
        "    \n",
        "    # Mapping tok2idx should contain each token or tag only once. \n",
        "    # To do so, you should:\n",
        "    # 1. extract unique tokens/tags from the tokens_or_tags variable, which is not\n",
        "    #    occur in special_tokens (because they could have non-empty intersection)\n",
        "    # 2. index them (for example, you can add them into the list idx2tok\n",
        "    # 3. for each token/tag save the index into tok2idx).\n",
        "    \n",
        "    ######################################\n",
        "    ######### YOUR CODE HERE #############\n",
        "    idx2tok = special_tokens\n",
        "    for i in tokens_or_tags:\n",
        "      for item in i:\n",
        "        if item not in idx2tok:\n",
        "          idx2tok.append(item)\n",
        "    for i in range(0, len(idx2tok)):\n",
        "      tok2idx[idx2tok[i]] = i\n",
        "    ######################################\n",
        "    \n",
        "    return tok2idx, idx2tok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi3oryIr3bDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "special_tokens = ['<UNK>', '<PAD>']\n",
        "special_tags = ['O']\n",
        "\n",
        "# Create dictionaries \n",
        "token2idx, idx2token = build_dict(train_tokens + validation_tokens, special_tokens)\n",
        "tag2idx, idx2tag = build_dict(train_tags, special_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FzcODFY3hGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def words2idxs(tokens_list):\n",
        "    return [token2idx[word] for word in tokens_list]\n",
        "\n",
        "def tags2idxs(tags_list):\n",
        "    return [tag2idx[tag] for tag in tags_list]\n",
        "\n",
        "def idxs2words(idxs):\n",
        "    return [idx2token[idx] for idx in idxs]\n",
        "\n",
        "def idxs2tags(idxs):\n",
        "    return [idx2tag[idx] for idx in idxs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fEkla3V367p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batches_generator(batch_size, tokens, tags,\n",
        "                      shuffle=True, allow_smaller_last_batch=True):\n",
        "    \"\"\"Generates padded batches of tokens and tags.\"\"\"\n",
        "    \n",
        "    n_samples = len(tokens)\n",
        "    if shuffle:\n",
        "        order = np.random.permutation(n_samples)\n",
        "    else:\n",
        "        order = np.arange(n_samples)\n",
        "\n",
        "    n_batches = n_samples // batch_size\n",
        "    if allow_smaller_last_batch and n_samples % batch_size:\n",
        "        n_batches += 1\n",
        "\n",
        "    for k in range(n_batches):\n",
        "        batch_start = k * batch_size\n",
        "        batch_end = min((k + 1) * batch_size, n_samples)\n",
        "        current_batch_size = batch_end - batch_start\n",
        "        x_list = []\n",
        "        y_list = []\n",
        "        max_len_token = 0\n",
        "        for idx in order[batch_start: batch_end]:\n",
        "            x_list.append(words2idxs(tokens[idx]))\n",
        "            y_list.append(tags2idxs(tags[idx]))\n",
        "            max_len_token = max(max_len_token, len(tags[idx]))\n",
        "            \n",
        "        # Fill in the data into numpy nd-arrays filled with padding indices.\n",
        "        x = np.ones([current_batch_size, max_len_token], dtype=np.int32) * token2idx['<PAD>']\n",
        "        y = np.ones([current_batch_size, max_len_token], dtype=np.int32) * tag2idx['O']\n",
        "        lengths = np.zeros(current_batch_size, dtype=np.int32)\n",
        "        for n in range(current_batch_size):\n",
        "            utt_len = len(x_list[n])\n",
        "            x[n, :utt_len] = x_list[n]\n",
        "            lengths[n] = utt_len\n",
        "            y[n, :utt_len] = y_list[n]\n",
        "        yield x, y, lengths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l_292rN4GR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WxZNrKO4OVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTMModel():\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX8uJcMY4O0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def declare_placeholders(self):\n",
        "    \"\"\"Specifies placeholders for the model.\"\"\"\n",
        "\n",
        "    # Placeholders for input and ground truth output.\n",
        "    self.input_batch = tf.placeholder(dtype=tf.int32, shape=[None, None], name='input_batch') \n",
        "    self.ground_truth_tags = tf.placeholder(dtype=tf.int32, shape=[None, None], name='ground_truth_tags') \n",
        "  \n",
        "    # Placeholder for lengths of the sequences.\n",
        "    self.lengths = tf.placeholder(dtype=tf.int32, shape=[None], name='lengths') \n",
        "    \n",
        "    # Placeholder for a dropout keep probability. If we don't feed\n",
        "    # a value for this placeholder, it will be equal to 1.0.\n",
        "    self.dropout_ph = tf.placeholder_with_default(tf.cast(1.0, tf.float32), shape=[])\n",
        "    \n",
        "    # Placeholder for a learning rate (tf.float32).\n",
        "    self.learning_rate_ph = tf.placeholder(dtype=tf.float32, name='learning_rate_ph') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMzu3UwY5GKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BiLSTMModel.__declare_placeholders = classmethod(declare_placeholders)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbrmEqeY5HUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_layers(self, vocabulary_size, embedding_dim, n_hidden_rnn, n_tags):\n",
        "    \"\"\"Specifies bi-LSTM architecture and computes logits for inputs.\"\"\"\n",
        "    \n",
        "    # Create embedding variable (tf.Variable) with dtype tf.float32\n",
        "    initial_embedding_matrix = np.random.randn(vocabulary_size, embedding_dim) / np.sqrt(embedding_dim)\n",
        "    embedding_matrix_variable = tf.Variable(initial_embedding_matrix, dtype=tf.float32, name='embeddings_matrix')\n",
        "    \n",
        "    # Create RNN cells (for example, tf.nn.rnn_cell.BasicLSTMCell) with n_hidden_rnn number of units \n",
        "    # and dropout (tf.nn.rnn_cell.DropoutWrapper), initializing all *_keep_prob with dropout placeholder.\n",
        "    forward_cell =  tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.BasicLSTMCell(num_units=n_hidden_rnn), input_keep_prob=self.dropout_ph, output_keep_prob=self.dropout_ph, state_keep_prob=self.dropout_ph)\n",
        "    backward_cell =  tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.BasicLSTMCell(num_units=n_hidden_rnn), input_keep_prob=self.dropout_ph, output_keep_prob=self.dropout_ph, state_keep_prob=self.dropout_ph)\n",
        "\n",
        "    # Look up embeddings for self.input_batch (tf.nn.embedding_lookup).\n",
        "    # Shape: [batch_size, sequence_len, embedding_dim].\n",
        "    embeddings =  tf.nn.embedding_lookup(embedding_matrix_variable, self.input_batch)\n",
        "    \n",
        "    # Pass them through Bidirectional Dynamic RNN (tf.nn.bidirectional_dynamic_rnn).\n",
        "    # Shape: [batch_size, sequence_len, 2 * n_hidden_rnn]. \n",
        "    # Also don't forget to initialize sequence_length as self.lengths and dtype as tf.float32.\n",
        "    (rnn_output_fw, rnn_output_bw), _ =  tf.nn.bidirectional_dynamic_rnn(forward_cell, backward_cell, embeddings, sequence_length=self.lengths, dtype=tf.float32)\n",
        "    rnn_output = tf.concat([rnn_output_fw, rnn_output_bw], axis=2)\n",
        "\n",
        "    # Dense layer on top.\n",
        "    # Shape: [batch_size, sequence_len, n_tags].   \n",
        "    self.logits = tf.layers.dense(rnn_output, n_tags, activation=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHM9l0GCC00F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BiLSTMModel.__build_layers = classmethod(build_layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxdOg4bsC3RB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_predictions(self):\n",
        "    \"\"\"Transforms logits to probabilities and finds the most probable tags.\"\"\"\n",
        "    \n",
        "    # Create softmax (tf.nn.softmax) function\n",
        "    softmax_output = tf.nn.softmax(self.logits)\n",
        "    \n",
        "    # Use argmax (tf.argmax) to get the most probable tags\n",
        "    # Don't forget to set axis=-1\n",
        "    # otherwise argmax will be calculated in a wrong way\n",
        "    self.predictions = tf.argmax(softmax_output, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDz_hqHSDKRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BiLSTMModel.__compute_predictions = classmethod(compute_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJv9oQgmDMDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_loss(self, n_tags, PAD_index):\n",
        "    \"\"\"Computes masked cross-entopy loss with logits.\"\"\"\n",
        "    \n",
        "    # Create cross entropy function function (tf.nn.softmax_cross_entropy_with_logits_v2)\n",
        "    ground_truth_tags_one_hot = tf.one_hot(self.ground_truth_tags, n_tags)\n",
        "    loss_tensor =  tf.nn.softmax_cross_entropy_with_logits_v2(ground_truth_tags_one_hot, self.logits)\n",
        "    \n",
        "    mask = tf.cast(tf.not_equal(self.input_batch, PAD_index), tf.float32)\n",
        "    # Create loss function which doesn't operate with <PAD> tokens (tf.reduce_mean)\n",
        "    # Be careful that the argument of tf.reduce_mean should be\n",
        "    # multiplication of mask and loss_tensor.\n",
        "    self.loss =  tf.reduce_mean(loss_tensor*mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4WNH6owEM5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BiLSTMModel.__compute_loss = classmethod(compute_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue68vqGnEOiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perform_optimization(self):\n",
        "    \"\"\"Specifies the optimizer and train_op for the model.\"\"\"\n",
        "    \n",
        "    # Create an optimizer (tf.train.AdamOptimizer)\n",
        "    self.optimizer =  tf.train.AdamOptimizer()\n",
        "    self.grads_and_vars = self.optimizer.compute_gradients(self.loss)\n",
        "    \n",
        "    # Gradient clipping (tf.clip_by_norm) for self.grads_and_vars\n",
        "    # Pay attention that you need to apply this operation only for gradients \n",
        "    # because self.grads_and_vars also contains variables.\n",
        "    # list comprehension might be useful in this case.\n",
        "    clip_norm = tf.cast(1.0, tf.float32)\n",
        "    self.grads_and_vars = [(tf.clip_by_norm(grad, clip_norm=clip_norm), var) for grad, var in self.grads_and_vars]\n",
        "    \n",
        "    self.train_op = self.optimizer.apply_gradients(self.grads_and_vars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM-WsmdVFljG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BiLSTMModel.__perform_optimization = classmethod(perform_optimization)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28TWc7nlFpHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_model(self, vocabulary_size, n_tags, embedding_dim, n_hidden_rnn, PAD_index):\n",
        "    self.__declare_placeholders()\n",
        "    self.__build_layers(vocabulary_size, embedding_dim, n_hidden_rnn, n_tags)\n",
        "    self.__compute_predictions()\n",
        "    self.__compute_loss(n_tags, PAD_index)\n",
        "    self.__perform_optimization()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2FXhxY0Fq9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BiLSTMModel.__init__ = classmethod(init_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTqF6vavFsoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_on_batch(self, session, x_batch, y_batch, lengths, learning_rate, dropout_keep_probability):\n",
        "    feed_dict = {self.input_batch: x_batch,\n",
        "                 self.ground_truth_tags: y_batch,\n",
        "                 self.learning_rate_ph: learning_rate,\n",
        "                 self.dropout_ph: dropout_keep_probability,\n",
        "                 self.lengths: lengths}\n",
        "    \n",
        "    session.run(self.train_op, feed_dict=feed_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWXEETF0Fu0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BiLSTMModel.train_on_batch = classmethod(train_on_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_hUKGeAFwZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_for_batch(self, session, x_batch, lengths):\n",
        "    ######################################\n",
        "    ######### YOUR CODE HERE #############\n",
        "    feed_dict = {self.input_batch: x_batch,\n",
        "                 self.lengths: lengths}\n",
        "    ######################################\n",
        "    predictions = session.run(self.predictions, feed_dict=feed_dict)\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5dzN4l0G1t-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BiLSTMModel.predict_for_batch = classmethod(predict_for_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9MD1Q1hG4F4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from evaluation import precision_recall_f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "netINyHfG7YJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_tags(model, session, token_idxs_batch, lengths):\n",
        "    \"\"\"Performs predictions and transforms indices to tokens and tags.\"\"\"\n",
        "    \n",
        "    tag_idxs_batch = model.predict_for_batch(session, token_idxs_batch, lengths)\n",
        "    \n",
        "    tags_batch, tokens_batch = [], []\n",
        "    for tag_idxs, token_idxs in zip(tag_idxs_batch, token_idxs_batch):\n",
        "        tags, tokens = [], []\n",
        "        for tag_idx, token_idx in zip(tag_idxs, token_idxs):\n",
        "            tags.append(idx2tag[tag_idx])\n",
        "            tokens.append(idx2token[token_idx])\n",
        "        tags_batch.append(tags)\n",
        "        tokens_batch.append(tokens)\n",
        "    return tags_batch, tokens_batch\n",
        "    \n",
        "    \n",
        "def eval_conll(model, session, tokens, tags, short_report=True):\n",
        "    \"\"\"Computes NER quality measures using CONLL shared task script.\"\"\"\n",
        "    \n",
        "    y_true, y_pred = [], []\n",
        "    for x_batch, y_batch, lengths in batches_generator(1, tokens, tags):\n",
        "        tags_batch, tokens_batch = predict_tags(model, session, x_batch, lengths)\n",
        "        if len(x_batch[0]) != len(tags_batch[0]):\n",
        "            raise Exception(\"Incorrect length of prediction for the input, \"\n",
        "                            \"expected length: %i, got: %i\" % (len(x_batch[0]), len(tags_batch[0])))\n",
        "        predicted_tags = []\n",
        "        ground_truth_tags = []\n",
        "        for gt_tag_idx, pred_tag, token in zip(y_batch[0], tags_batch[0], tokens_batch[0]): \n",
        "            if token != '<PAD>':\n",
        "                ground_truth_tags.append(idx2tag[gt_tag_idx])\n",
        "                predicted_tags.append(pred_tag)\n",
        "\n",
        "        # We extend every prediction and ground truth sequence with 'O' tag\n",
        "        # to indicate a possible end of entity.\n",
        "        y_true.extend(ground_truth_tags + ['O'])\n",
        "        y_pred.extend(predicted_tags + ['O'])\n",
        "        \n",
        "    results = precision_recall_f1(y_true, y_pred, print_results=True, short_report=short_report)\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4QOIlU5G-WV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "tf.reset_default_graph()\n",
        "\n",
        "model = BiLSTMModel(vocabulary_size=len(idx2token), n_tags=len(idx2tag), embedding_dim=200, n_hidden_rnn=200, PAD_index=token2idx['<PAD>'])\n",
        "\n",
        "batch_size = 32\n",
        "n_epochs = 7 # values that has been tried in experiments: 4, 7, 10\n",
        "learning_rate = 0.005\n",
        "learning_rate_decay = math.sqrt(2)\n",
        "dropout_keep_probability = 0.95 # values that has been tried in experiments: 0.1, 0.5, 0.9, 0.95"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKTtDjL9IHwo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "de32050f-0367-4ce7-c9b0-65d98cbb1617"
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "print('Start training... \\n')\n",
        "for epoch in range(n_epochs):\n",
        "    # For each epoch evaluate the model on train and validation data\n",
        "    print('-' * 20 + ' Epoch {} '.format(epoch+1) + 'of {} '.format(n_epochs) + '-' * 20)\n",
        "    print('Train data evaluation:')\n",
        "    eval_conll(model, sess, train_tokens, train_tags, short_report=True)\n",
        "    print('Validation data evaluation:')\n",
        "    eval_conll(model, sess, validation_tokens, validation_tags, short_report=True)\n",
        "    \n",
        "    # Train the model\n",
        "    for x_batch, y_batch, lengths in batches_generator(batch_size, train_tokens, train_tags):\n",
        "        model.train_on_batch(sess, x_batch, y_batch, lengths, learning_rate, dropout_keep_probability)\n",
        "        \n",
        "    # Decaying the learning rate\n",
        "    learning_rate = learning_rate / learning_rate_decay\n",
        "    \n",
        "print('...training finished.')"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training... \n",
            "\n",
            "-------------------- Epoch 1 of 7 --------------------\n",
            "Train data evaluation:\n",
            "processed 105778 tokens with 4489 phrases; found: 77596 phrases; correct: 156.\n",
            "\n",
            "precision:  0.20%; recall:  3.48%; F1:  0.38\n",
            "\n",
            "Validation data evaluation:\n",
            "processed 12836 tokens with 537 phrases; found: 9483 phrases; correct: 20.\n",
            "\n",
            "precision:  0.21%; recall:  3.72%; F1:  0.40\n",
            "\n",
            "-------------------- Epoch 2 of 7 --------------------\n",
            "Train data evaluation:\n",
            "processed 105778 tokens with 4489 phrases; found: 87 phrases; correct: 9.\n",
            "\n",
            "precision:  10.34%; recall:  0.20%; F1:  0.39\n",
            "\n",
            "Validation data evaluation:\n",
            "processed 12836 tokens with 537 phrases; found: 10 phrases; correct: 2.\n",
            "\n",
            "precision:  20.00%; recall:  0.37%; F1:  0.73\n",
            "\n",
            "-------------------- Epoch 3 of 7 --------------------\n",
            "Train data evaluation:\n",
            "processed 105778 tokens with 4489 phrases; found: 3282 phrases; correct: 483.\n",
            "\n",
            "precision:  14.72%; recall:  10.76%; F1:  12.43\n",
            "\n",
            "Validation data evaluation:\n",
            "processed 12836 tokens with 537 phrases; found: 264 phrases; correct: 37.\n",
            "\n",
            "precision:  14.02%; recall:  6.89%; F1:  9.24\n",
            "\n",
            "-------------------- Epoch 4 of 7 --------------------\n",
            "Train data evaluation:\n",
            "processed 105778 tokens with 4489 phrases; found: 3559 phrases; correct: 930.\n",
            "\n",
            "precision:  26.13%; recall:  20.72%; F1:  23.11\n",
            "\n",
            "Validation data evaluation:\n",
            "processed 12836 tokens with 537 phrases; found: 270 phrases; correct: 83.\n",
            "\n",
            "precision:  30.74%; recall:  15.46%; F1:  20.57\n",
            "\n",
            "-------------------- Epoch 5 of 7 --------------------\n",
            "Train data evaluation:\n",
            "processed 105778 tokens with 4489 phrases; found: 5195 phrases; correct: 2201.\n",
            "\n",
            "precision:  42.37%; recall:  49.03%; F1:  45.46\n",
            "\n",
            "Validation data evaluation:\n",
            "processed 12836 tokens with 537 phrases; found: 473 phrases; correct: 134.\n",
            "\n",
            "precision:  28.33%; recall:  24.95%; F1:  26.53\n",
            "\n",
            "-------------------- Epoch 6 of 7 --------------------\n",
            "Train data evaluation:\n",
            "processed 105778 tokens with 4489 phrases; found: 4957 phrases; correct: 2354.\n",
            "\n",
            "precision:  47.49%; recall:  52.44%; F1:  49.84\n",
            "\n",
            "Validation data evaluation:\n",
            "processed 12836 tokens with 537 phrases; found: 440 phrases; correct: 150.\n",
            "\n",
            "precision:  34.09%; recall:  27.93%; F1:  30.71\n",
            "\n",
            "-------------------- Epoch 7 of 7 --------------------\n",
            "Train data evaluation:\n",
            "processed 105778 tokens with 4489 phrases; found: 4913 phrases; correct: 3411.\n",
            "\n",
            "precision:  69.43%; recall:  75.99%; F1:  72.56\n",
            "\n",
            "Validation data evaluation:\n",
            "processed 12836 tokens with 537 phrases; found: 519 phrases; correct: 181.\n",
            "\n",
            "precision:  34.87%; recall:  33.71%; F1:  34.28\n",
            "\n",
            "...training finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYnER9mUISLY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92082b77-a2b5-4e54-f68f-ef22066319b2"
      },
      "source": [
        "\n",
        "print('-' * 20 + ' Train set quality: ' + '-' * 20)\n",
        "train_results = eval_conll(model, sess, train_tokens, train_tags, short_report=False)\n",
        "\n",
        "print('-' * 20 + ' Validation set quality: ' + '-' * 20)\n",
        "validation_results = eval_conll(model, sess, validation_tokens, validation_tags, short_report=False)\n",
        "\n",
        "print('-' * 20 + ' Test set quality: ' + '-' * 20)\n",
        "test_results = eval_conll(model, sess, test_tokens, test_tags, short_report=False)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------- Train set quality: --------------------\n",
            "processed 105778 tokens with 4489 phrases; found: 4687 phrases; correct: 3793.\n",
            "\n",
            "precision:  80.93%; recall:  84.50%; F1:  82.67\n",
            "\n",
            "\t     company: precision:   90.67%; recall:   92.22%; F1:   91.44; predicted:   654\n",
            "\n",
            "\t    facility: precision:   75.35%; recall:   85.67%; F1:   80.18; predicted:   357\n",
            "\n",
            "\t     geo-loc: precision:   88.58%; recall:   95.78%; F1:   92.04; predicted:  1077\n",
            "\n",
            "\t       movie: precision:   15.79%; recall:    4.41%; F1:    6.90; predicted:    19\n",
            "\n",
            "\t musicartist: precision:   61.39%; recall:   41.81%; F1:   49.74; predicted:   158\n",
            "\n",
            "\t       other: precision:   78.83%; recall:   85.60%; F1:   82.08; predicted:   822\n",
            "\n",
            "\t      person: precision:   81.30%; recall:   95.71%; F1:   87.92; predicted:  1043\n",
            "\n",
            "\t     product: precision:   67.65%; recall:   79.56%; F1:   73.12; predicted:   374\n",
            "\n",
            "\t  sportsteam: precision:   72.57%; recall:   58.53%; F1:   64.80; predicted:   175\n",
            "\n",
            "\t      tvshow: precision:   12.50%; recall:    1.72%; F1:    3.03; predicted:     8\n",
            "\n",
            "-------------------- Validation set quality: --------------------\n",
            "processed 12836 tokens with 537 phrases; found: 420 phrases; correct: 188.\n",
            "\n",
            "precision:  44.76%; recall:  35.01%; F1:  39.29\n",
            "\n",
            "\t     company: precision:   66.67%; recall:   53.85%; F1:   59.57; predicted:    84\n",
            "\n",
            "\t    facility: precision:   30.43%; recall:   41.18%; F1:   35.00; predicted:    46\n",
            "\n",
            "\t     geo-loc: precision:   68.35%; recall:   47.79%; F1:   56.25; predicted:    79\n",
            "\n",
            "\t       movie: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:     0\n",
            "\n",
            "\t musicartist: precision:   10.00%; recall:    3.57%; F1:    5.26; predicted:    10\n",
            "\n",
            "\t       other: precision:   27.91%; recall:   29.63%; F1:   28.74; predicted:    86\n",
            "\n",
            "\t      person: precision:   37.80%; recall:   27.68%; F1:   31.96; predicted:    82\n",
            "\n",
            "\t     product: precision:   24.00%; recall:   17.65%; F1:   20.34; predicted:    25\n",
            "\n",
            "\t  sportsteam: precision:   28.57%; recall:   10.00%; F1:   14.81; predicted:     7\n",
            "\n",
            "\t      tvshow: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:     1\n",
            "\n",
            "-------------------- Test set quality: --------------------\n",
            "processed 13258 tokens with 604 phrases; found: 524 phrases; correct: 223.\n",
            "\n",
            "precision:  42.56%; recall:  36.92%; F1:  39.54\n",
            "\n",
            "\t     company: precision:   51.72%; recall:   35.71%; F1:   42.25; predicted:    58\n",
            "\n",
            "\t    facility: precision:   42.86%; recall:   44.68%; F1:   43.75; predicted:    49\n",
            "\n",
            "\t     geo-loc: precision:   71.77%; recall:   53.94%; F1:   61.59; predicted:   124\n",
            "\n",
            "\t       movie: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:     1\n",
            "\n",
            "\t musicartist: precision:   11.54%; recall:   11.11%; F1:   11.32; predicted:    26\n",
            "\n",
            "\t       other: precision:   23.66%; recall:   30.10%; F1:   26.50; predicted:   131\n",
            "\n",
            "\t      person: precision:   48.81%; recall:   39.42%; F1:   43.62; predicted:    84\n",
            "\n",
            "\t     product: precision:   12.12%; recall:   14.29%; F1:   13.11; predicted:    33\n",
            "\n",
            "\t  sportsteam: precision:   28.57%; recall:   12.90%; F1:   17.78; predicted:    14\n",
            "\n",
            "\t      tvshow: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:     4\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeiLdMRiKi7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}